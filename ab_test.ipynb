{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Algoritmo de limpieza de la base de datos, para llegar al resultado deseado."
      ],
      "metadata": {
        "id": "6X0n-Osdw2AN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/Datos meli.csv',sep=';')\n",
        "df['item_id'] = df['item_id'].fillna(0)\n",
        "df = df[df['event_name'] != 'SEARCH']\n",
        "df = df.sort_values(['user_id','timestamp','item_id'], ascending=[False,False,False])\n",
        "# Eliminar filas consecutivas con valores duplicados en col1, col2 y col3\n",
        "df['is_duplicate'] = (\n",
        "    (df['event_name'] == df['event_name'].shift(-1)) &\n",
        "    (df['item_id'] == df['item_id'].shift(-1)) &\n",
        "    (df['user_id'] == df['user_id'].shift(-1)) &\n",
        "    (df['event_name'] != 'BUY'))\n",
        "\n",
        "# Paso 2: Identificar los índices a eliminar (solo la fila con el índice mayor)\n",
        "indices_to_remove = df[df['is_duplicate']].index + 1\n",
        "\n",
        "# Paso 3: Filtrar el DataFrame para eliminar las filas con los índices mayores\n",
        "df = df[~df.index.isin(indices_to_remove)]\n",
        "\n",
        "# Paso 4: Eliminar la columna auxiliar\n",
        "df = df.drop(columns='is_duplicate')\n",
        "\n",
        "mapeo = {\n",
        "    'SEARCH': 0,\n",
        "    'PRODUCT': 1,\n",
        "    'CHECKOUT_1': 2,\n",
        "    'CHECKOUT_2': 3,\n",
        "    'CHECKOUT_3': 4,\n",
        "    'BUY': 5}\n",
        "\n",
        "# Aplicar el mapeo a la columna y renombrarla a event_num\n",
        "df['event_num'] = df['event_name'].map(mapeo)\n",
        "df = df.reset_index(drop=True)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "j8tcLq1AD2JT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eliminar_filas(df):\n",
        "    indices_a_eliminar = []\n",
        "    for i in range(len(df) - 1):\n",
        "        if df.loc[i + 1, 'event_num'] >= df.loc[i, 'event_num'] and df.loc[i + 1, 'event_num'] != 5 and df.loc[i + 1, 'item_id'] == df.loc[i, 'item_id']and df.loc[i + 1, 'user_id'] == df.loc[i, 'user_id']:\n",
        "            indices_a_eliminar.append(i + 1)\n",
        "\n",
        "    if indices_a_eliminar:\n",
        "        df = df.drop(indices_a_eliminar).reset_index(drop=True)\n",
        "        df = eliminar_filas(df)  # Llamada recursiva\n",
        "    return df\n",
        "\n",
        "df_filtered = eliminar_filas(df)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ScdM3izaD1-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_buy = df[df['event_name'] == 'BUY']\n",
        "df_filtered['date'] = pd.to_datetime(df_filtered['timestamp']).dt.date\n",
        "df_buy['date'] = pd.to_datetime(df_buy['timestamp']).dt.date\n",
        "df_merged = pd.merge(df_filtered, df_buy[['item_id', 'user_id', 'date']], on=['item_id', 'user_id', 'date'], how='inner')\n",
        "\n",
        "def eliminar_filas(df_merged):\n",
        "    indices_a_eliminar = []\n",
        "    for i in range(len(df_merged) - 1):\n",
        "        if df_merged.loc[i + 1, 'event_num'] >= df_merged.loc[i, 'event_num'] and df_merged.loc[i + 1, 'event_num'] != 5 and df_merged.loc[i + 1, 'item_id'] == df_merged.loc[i, 'item_id']and df_merged.loc[i + 1, 'user_id'] == df_merged.loc[i, 'user_id']:\n",
        "            indices_a_eliminar.append(i + 1)\n",
        "\n",
        "    if indices_a_eliminar:\n",
        "        df_merged = df_merged.drop(indices_a_eliminar).reset_index(drop=True)\n",
        "        df_merged = eliminar_filas(df_merged)  # Llamada recursiva\n",
        "    return df_merged\n",
        "\n",
        "df_merged_final = eliminar_filas(df_merged)\n",
        "print(df_merged_final)\n",
        "df_merged_final = df_merged_final.drop_duplicates()\n",
        "df_merged_final.to_csv('/content/df_merged_final.csv', index = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_JdBkaXyv750",
        "outputId": "948c4406-9856-4bda-9bee-5cdc88dc135e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-97b2f780852b>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_buy['date'] = pd.to_datetime(df_buy['timestamp']).dt.date\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      event_name      item_id                     timestamp site  \\\n",
            "0            BUY  356305667.0  2021-08-02T08:35:58.583-0400  MLA   \n",
            "1     CHECKOUT_3  356305667.0  2021-08-02T08:34:42.956-0400  MLA   \n",
            "2     CHECKOUT_2  356305667.0  2021-08-02T08:32:56.100-0400  MLA   \n",
            "3        PRODUCT  356305667.0  2021-08-02T08:32:07.822-0400  MLA   \n",
            "4            BUY  393529429.0  2021-08-02T11:58:20.201-0400  MLA   \n",
            "...          ...          ...                           ...  ...   \n",
            "5038     PRODUCT  789004239.0  2021-08-02T19:45:44.269-0400  MLA   \n",
            "5039         BUY   79821609.0  2021-08-02T08:54:38.662-0400  MLA   \n",
            "5040  CHECKOUT_3   79821609.0  2021-08-02T08:54:18.937-0400  MLA   \n",
            "5041  CHECKOUT_2   79821609.0  2021-08-02T08:53:45.257-0400  MLA   \n",
            "5042  CHECKOUT_1   79821609.0  2021-08-02T08:53:38.860-0400  MLA   \n",
            "\n",
            "                                            experiments  user_id  event_num  \\\n",
            "0     {buyingflow/user-track=6796, buyingflow/addres...  9975941          5   \n",
            "1     {buyingflow/user-track=6796, buyingflow/addres...  9975941          4   \n",
            "2     {buyingflow/user-track=6796, buyingflow/addres...  9975941          3   \n",
            "3     {search/remove-ecn-tag=4954, vip/showV2V3BoxMe...  9975941          1   \n",
            "4                          {buyingflow/user-track=6796}  9963531          5   \n",
            "...                                                 ...      ...        ...   \n",
            "5038  {search/remove-ecn-tag=4954, vip/showV2V3BoxMe...      466          1   \n",
            "5039  {buyingflow/user-track=6796, buyingflow/addres...      311          5   \n",
            "5040  {buyingflow/user-track=6796, buyingflow/addres...      311          4   \n",
            "5041  {buyingflow/user-track=6796, buyingflow/addres...      311          3   \n",
            "5042  {buyingflow/user-track=6796, buyingflow/escWeb...      311          2   \n",
            "\n",
            "            date  \n",
            "0     2021-08-02  \n",
            "1     2021-08-02  \n",
            "2     2021-08-02  \n",
            "3     2021-08-02  \n",
            "4     2021-08-02  \n",
            "...          ...  \n",
            "5038  2021-08-02  \n",
            "5039  2021-08-02  \n",
            "5040  2021-08-02  \n",
            "5041  2021-08-02  \n",
            "5042  2021-08-02  \n",
            "\n",
            "[5043 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar el DataFrame\n",
        "df = pd.read_csv('/content/df_merged_final.csv')\n",
        "\n",
        "# Convertir 'timestamp' a datetime\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "# Función para concatenar los experimentos\n",
        "def concatenate_experiments(group):\n",
        "    return ''.join(group['experiments'])\n",
        "\n",
        "# Filtrar y ordenar para seleccionar el timestamp más antiguo cuando 'event_num' es 5\n",
        "df_sorted = df.sort_values(by=['user_id', 'item_id', 'event_num', 'timestamp'])\n",
        "df_filtered = df_sorted.drop_duplicates(subset=['user_id', 'item_id', 'event_num'], keep='first')\n",
        "\n",
        "# Agrupar por 'user_id' y 'item_id' y concatenar los experimentos por 'event_num'\n",
        "df_grouped = df_filtered.groupby(['user_id', 'item_id']).apply(concatenate_experiments).reset_index(name='concatenated_experiments')\n",
        "df_grouped['count'] = df_grouped.groupby('concatenated_experiments')['concatenated_experiments'].transform('count')\n",
        "#df_grouped = df_grouped.drop(columns=['user_id','item_id'])\n",
        "\n",
        "# Guardar el resultado en un archivo CSV\n",
        "df_grouped.to_csv('/content/df_concatenated_experiments.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "gnBwZFevgoOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo de conteo de ocurrencias por un experimento dado para calcular tamaños de muestras"
      ],
      "metadata": {
        "id": "IY04O88UI5A4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/Datos meli.csv',sep=\";\")\n",
        "df_1 = df[df['experiments']==\"{search/remove-ecn-tag=4954, vip/showV2V3BoxMessages=6430, search/tendency-landing-enabled-MLA=6980, pdp/viewItemPageMigrationDesktopReviewsNoTabs=4856, cookiesConsentBanner=DEFAULT, vip/shippingCalculatorMigrationModalExperiment=6551, vip/carousel-v2p-above-the-fold=6786, pdp/viewItemPageMigrationReturns=5208, vip/seller-with-tooltip=4692}\"].count()\n",
        "print(df_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOLXbjV3GRoQ",
        "outputId": "6183ee8d-5027-46a3-9744-c53347831fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "event_name     2184\n",
            "item_id        2184\n",
            "timestamp      2184\n",
            "site           2184\n",
            "experiments    2184\n",
            "user_id        2184\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SRM test - mediante test chi-cuadrado con una significancia de 0.05"
      ],
      "metadata": {
        "id": "8g21fvgIIowx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Define the observed number of users in each group\n",
        "observed = [894, 163]  # Example for Version A, Version B, Version C, and Version D\n",
        "\n",
        "# Define the expected number of users assuming an equal split across all groups\n",
        "total_users = sum(observed)\n",
        "expected = [total_users / len(observed)] * len(observed)  # Expected split\n",
        "\n",
        "# Perform the chi-square goodness of fit test\n",
        "chi2_stat, p_value = stats.chisquare(f_obs=observed, f_exp=expected)\n",
        "\n",
        "print(f\"Chi-square Statistic: {chi2_stat}\")\n",
        "print(f\"p-value: {p_value}\")\n",
        "\n",
        "# Interpretation\n",
        "if p_value < 0.05:\n",
        "    print(\"The observed distribution differs significantly from the expected distribution. Possible SRM detected.\")\n",
        "else:\n",
        "    print(\"No significant difference from the expected distribution. SRM is unlikely.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CtK27UiETv2",
        "outputId": "5dcd3ce1-f81e-4340-b989-a775dc898bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-square Statistic: 207.21076233183857\n",
            "p-value: 5.577214777607944e-47\n",
            "The observed distribution differs significantly from the expected distribution. Possible SRM detected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test binomial para rechazo de hipotesis nulas (EJEMPLO):"
      ],
      "metadata": {
        "id": "8Lh6HINWIg2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Number of conversions in Version A and B\n",
        "conversions_A = 44\n",
        "conversions_B = 59\n",
        "\n",
        "# Number of users in Version A and B\n",
        "users_A = 5512\n",
        "users_B = 5098\n",
        "\n",
        "# Conversion rate for Version A (used as the hypothesized probability of success under H0)\n",
        "p = conversions_A / users_A\n",
        "\n",
        "# Perform the binomial test for Version B\n",
        "result = stats.binomtest(conversions_B, n=users_B, p=p, alternative='greater')\n",
        "\n",
        "print(f\"p-value: {result.pvalue}\")\n"
      ],
      "metadata": {
        "id": "-WazbllaQOGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8742d7fa-2222-48da-ffac-781f2125f17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p-value: 0.003979976890238631\n"
          ]
        }
      ]
    }
  ]
}